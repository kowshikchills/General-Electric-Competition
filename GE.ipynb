{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named flask",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e3a198d85699>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mflask\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFlask\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mflask_cors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_origin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMySQLdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mframe_query\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named flask"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "from flask_cors import CORS, cross_origin\n",
    "import MySQLdb\n",
    "import pandas\n",
    "from pandas.io.sql import frame_query\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_extraction import DictVectorizer \n",
    "from sklearn.externals import joblib\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def BasicNight():\n",
    "        #BasicFuntion Night \n",
    "        db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "        cursor = db.cursor()\n",
    "        sql = \"SELECT * FROM answers WHERE finished='1'\"\n",
    "        data = frame_query(sql, db)\n",
    "        #BasicFuntion Night \n",
    "\n",
    "        df_training = data\n",
    "        df_train = df_training[df_training.columns[2:9]]\n",
    "\n",
    "        Y_train = df_train['L11P'].values\n",
    "        del df_train['L11P']\n",
    "        #ENCODING\n",
    "        X_train = df_train.to_dict('records')\n",
    "        X_tr = []\n",
    "        X_tr.extend(X_train)\n",
    "        #One Hot Encoding \n",
    "        enc = DictVectorizer(sparse = True)\n",
    "        X_encoded_train =enc.fit_transform(X_tr)\n",
    "        estimator = GradientBoostingClassifier() \n",
    "        estimator.fit(X_encoded_train.toarray(),Y_train)\n",
    "        joblib.dump(estimator, 'Estbasic.pkl') \n",
    "        return 'success'\n",
    "\n",
    "@app.route(\"/pred\")\n",
    "def Basicpred():\n",
    "    URL = 'DUMB.csv'\n",
    "    DUMB = pandas.read_csv(URL)\n",
    "    df_DUMB = DUMB[DUMB.columns[1:7]]\n",
    "\n",
    "    db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "    cursor = db.cursor()\n",
    "    sql = \"SELECT * FROM answers WHERE finished='0'\"\n",
    "    data = frame_query(sql, db)\n",
    "\n",
    "    df_test = data[data.columns[2:8]]\n",
    "    frames = [ df_DUMB,df_test]\n",
    "    df_WH = pandas.concat(frames)\n",
    "\n",
    "    #ENCODING\n",
    "    X_test = df_WH.to_dict('records')\n",
    "    X_te = []\n",
    "    X_te.extend(X_test)\n",
    "\n",
    "\n",
    "    encoder = DictVectorizer(sparse = True)\n",
    "    X_encoded_test = encoder.fit_transform(X_te)\n",
    "    clf2 = joblib.load('Estbasic.pkl') \n",
    "    Predictions = clf2.predict(X_encoded_test.toarray()[-1])\n",
    "    return str(int(Predictions))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L21Night():\n",
    "        #L21 Night\n",
    "        db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "        cursor = db.cursor()\n",
    "        sql = \"SELECT * FROM answers WHERE finished='1'\"\n",
    "        data = frame_query(sql, db)\n",
    "        df_training = data\n",
    "        df_train = df_training[list(data.columns[2:8])+ list(data.columns[10:16])]\n",
    "        Y_train = df_train['L21P'].values\n",
    "        del df_train['L21P']\n",
    "        #ENCODING\n",
    "        X_train = df_train.to_dict('records')\n",
    "        X_tr = []\n",
    "        X_tr.extend(X_train)\n",
    "        #One Hot Encoding \n",
    "        enc = DictVectorizer(sparse = True)\n",
    "        X_encoded_train =enc.fit_transform(X_tr)\n",
    "        estimator = GradientBoostingClassifier() \n",
    "        estimator.fit(X_encoded_train.toarray(),Y_train)\n",
    "        joblib.dump(estimator, 'EstL21.pkl') \n",
    "        return 'success'\n",
    "\n",
    "def L21pred():\n",
    "    URL = 'DUMB.csv'\n",
    "    DUMB = pandas.read_csv(URL)\n",
    "    df_DUMB = DUMB[DUMB.columns[1:7]+ DUMB.columns[9:14]]\n",
    "\n",
    "    db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "    cursor = db.cursor()\n",
    "    sql = \"SELECT * FROM answers WHERE finished='0'\"\n",
    "    data = frame_query(sql, db)\n",
    "\n",
    "    df_test = data[list(data.columns[2:8])+ list(data.columns[10:15])]\n",
    "    frames = [ df_DUMB,df_test]\n",
    "    df_WH = pandas.concat(frames)\n",
    "\n",
    "    #ENCODING\n",
    "    X_test = df_WH.to_dict('records')\n",
    "    X_te = []\n",
    "    X_te.extend(X_test)\n",
    "\n",
    "\n",
    "    encoder = DictVectorizer(sparse = True)\n",
    "    X_encoded_test = encoder.fit_transform(X_te)\n",
    "    clf2 = joblib.load('EstL21.pkl') \n",
    "    Predictions = clf2.predict(X_encoded_test.toarray()[-1])\n",
    "    return str(int(Predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L22Night():\n",
    "        #L21 Night\n",
    "        db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "        cursor = db.cursor()\n",
    "        sql = \"SELECT * FROM answers WHERE finished='1'\"\n",
    "        data = frame_query(sql, db)\n",
    "        df_training = data\n",
    "        df_train = df_training[list(data.columns[2:8])+ list(data.columns[17:22])]\n",
    "        Y_train = df_train['L22P'].values\n",
    "        del df_train['L22P']\n",
    "        #ENCODING\n",
    "        X_train = df_train.to_dict('records')\n",
    "        X_tr = []\n",
    "        X_tr.extend(X_train)\n",
    "        #One Hot Encoding \n",
    "        enc = DictVectorizer(sparse = True)\n",
    "        X_encoded_train =enc.fit_transform(X_tr)\n",
    "        estimator = GradientBoostingClassifier() \n",
    "        estimator.fit(X_encoded_train.toarray(),Y_train)\n",
    "        joblib.dump(estimator, 'EstL22.pkl') \n",
    "        return 'success'\n",
    "\n",
    "def L22pred():\n",
    "    URL = 'DUMB.csv'\n",
    "    DUMB = pandas.read_csv(URL)\n",
    "    df_DUMB = DUMB[DUMB.columns[1:7]+ DUMB.columns[16:20]] \n",
    "\n",
    "    db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "    cursor = db.cursor()\n",
    "    sql = \"SELECT * FROM answers WHERE finished='0'\"\n",
    "    data = frame_query(sql, db)\n",
    "\n",
    "    df_test = data[list(data.columns[2:8])+ list(data.columns[17:21])]\n",
    "    frames = [ df_DUMB,df_test]\n",
    "    df_WH = pandas.concat(frames)\n",
    "\n",
    "    #ENCODING\n",
    "    X_test = df_WH.to_dict('records')\n",
    "    X_te = []\n",
    "    X_te.extend(X_test)\n",
    "\n",
    "\n",
    "    encoder = DictVectorizer(sparse = True)\n",
    "    X_encoded_test = encoder.fit_transform(X_te)\n",
    "    clf2 = joblib.load('EstL22.pkl') \n",
    "    Predictions = clf2.predict(X_encoded_test.toarray()[-1])\n",
    "    return str(int(Predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L23Night():\n",
    "        #L21 Night\n",
    "        db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "        cursor = db.cursor()\n",
    "        sql = \"SELECT * FROM answers WHERE finished='1'\"\n",
    "        data = frame_query(sql, db)\n",
    "        df_training = data\n",
    "        df_train = df_training[list(data.columns[2:8])+ list(data.columns[23:28])]\n",
    "        Y_train = df_train['L23P'].values\n",
    "        del df_train['L23P']\n",
    "        #ENCODING\n",
    "        X_train = df_train.to_dict('records')\n",
    "        X_tr = []\n",
    "        X_tr.extend(X_train)\n",
    "        #One Hot Encoding \n",
    "        enc = DictVectorizer(sparse = True)\n",
    "        X_encoded_train =enc.fit_transform(X_tr)\n",
    "        estimator = GradientBoostingClassifier() \n",
    "        estimator.fit(X_encoded_train.toarray(),Y_train)\n",
    "        joblib.dump(estimator, 'EstL23.pkl') \n",
    "        return 'success'\n",
    "\n",
    "def L23pred():\n",
    "    URL = 'DUMB.csv'\n",
    "    DUMB = pandas.read_csv(URL)\n",
    "    df_DUMB = DUMB[DUMB.columns[1:7]+ DUMB.columns[22:26]] \n",
    "\n",
    "    db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "    cursor = db.cursor()\n",
    "    sql = \"SELECT * FROM answers WHERE finished='0'\"\n",
    "    data = frame_query(sql, db)\n",
    "\n",
    "    df_test = data[list(data.columns[2:8])+ list(data.columns[23:27])]\n",
    "    frames = [ df_DUMB,df_test]\n",
    "    df_WH = pandas.concat(frames)\n",
    "\n",
    "    #ENCODING\n",
    "    X_test = df_WH.to_dict('records')\n",
    "    X_te = []\n",
    "    X_te.extend(X_test)\n",
    "\n",
    "\n",
    "    encoder = DictVectorizer(sparse = True)\n",
    "    X_encoded_test = encoder.fit_transform(X_te)\n",
    "    clf2 = joblib.load('EstL23.pkl') \n",
    "    Predictions = clf2.predict(X_encoded_test.toarray()[-1])\n",
    "    return str(int(Predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L24Night():\n",
    "        #L21 Night\n",
    "        db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "        cursor = db.cursor()\n",
    "        sql = \"SELECT * FROM answers WHERE finished='1'\"\n",
    "        data = frame_query(sql, db)\n",
    "        df_training = data\n",
    "        df_train = df_training[list(data.columns[2:8])+ list(data.columns[29:34])]\n",
    "        Y_train = df_train['L24P'].values\n",
    "        del df_train['L24P']\n",
    "        #ENCODING\n",
    "        X_train = df_train.to_dict('records')\n",
    "        X_tr = []\n",
    "        X_tr.extend(X_train)\n",
    "        #One Hot Encoding \n",
    "        enc = DictVectorizer(sparse = True)\n",
    "        X_encoded_train =enc.fit_transform(X_tr)\n",
    "        estimator = GradientBoostingClassifier() \n",
    "        estimator.fit(X_encoded_train.toarray(),Y_train)\n",
    "        joblib.dump(estimator, 'EstL24.pkl') \n",
    "        return 'success'\n",
    "\n",
    "def L24pred():\n",
    "    URL = 'DUMB.csv'\n",
    "    DUMB = pandas.read_csv(URL)\n",
    "    df_DUMB = DUMB[DUMB.columns[1:7]+ DUMB.columns[28:32]] \n",
    "\n",
    "    db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "    cursor = db.cursor()\n",
    "    sql = \"SELECT * FROM answers WHERE finished='0'\"\n",
    "    data = frame_query(sql, db)\n",
    "\n",
    "    df_test = data[list(data.columns[2:8])+ list(data.columns[29:33])]\n",
    "    frames = [ df_DUMB,df_test]\n",
    "    df_WH = pandas.concat(frames)\n",
    "\n",
    "    #ENCODING\n",
    "    X_test = df_WH.to_dict('records')\n",
    "    X_te = []\n",
    "    X_te.extend(X_test)\n",
    "\n",
    "\n",
    "    encoder = DictVectorizer(sparse = True)\n",
    "    X_encoded_test = encoder.fit_transform(X_te)\n",
    "    clf2 = joblib.load('EstL24.pkl') \n",
    "    Predictions = clf2.predict(X_encoded_test.toarray()[-1])\n",
    "    return str(int(Predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pandas\n",
    "from pandas.io.sql import frame_query\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_extraction import DictVectorizer \n",
    "from sklearn.externals import joblib\n",
    "URL = 'answers(1).csv'\n",
    "data = pandas.read_csv(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def BasicNight():\n",
    "        #BasicFuntion Night \n",
    "        URL = 'answers(1).csv'\n",
    "        data = pandas.read_csv(URL)\n",
    "        data = data[data.finished != 0] \n",
    "        #BasicFuntion Night \n",
    "\n",
    "        df_training = data\n",
    "        df_train = df_training[df_training.columns[2:9]]\n",
    "\n",
    "        Y_train = df_train['L11P'].values\n",
    "        del df_train['L11P']\n",
    "        #ENCODING\n",
    "        X_train = df_train.to_dict('records')\n",
    "        X_tr = []\n",
    "        X_tr.extend(X_train)\n",
    "        #One Hot Encoding \n",
    "        enc = DictVectorizer(sparse = True)\n",
    "        X_encoded_train =enc.fit_transform(X_tr)\n",
    "        estimator = GradientBoostingClassifier() \n",
    "        estimator.fit(X_encoded_train.toarray(),Y_train)\n",
    "        joblib.dump(estimator, 'Estbasic.pkl') \n",
    "        return 'success'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BasicNight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Basicpred():\n",
    "    URL = 'DUMB.csv'\n",
    "    DUMB = pandas.read_csv(URL)\n",
    "    df_DUMB = DUMB[DUMB.columns[1:7]]\n",
    "\n",
    "    #db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "    #cursor = db.cursor()\n",
    "    #sql = \"SELECT * FROM answers WHERE finished='0'\"\n",
    "    #data = frame_query(sql, db)\n",
    "    URL = 'answers(1).csv'\n",
    "    data = pandas.read_csv(URL)\n",
    "    data = data[data.finished != 1] \n",
    "    df_test = data[data.columns[2:8]]\n",
    "    frames = [ df_DUMB,df_test]\n",
    "    df_WH = pandas.concat(frames)\n",
    "\n",
    "    #ENCODING\n",
    "    X_test = df_WH.to_dict('records')\n",
    "    X_te = []\n",
    "    X_te.extend(X_test)\n",
    "\n",
    "\n",
    "    encoder = DictVectorizer(sparse = True)\n",
    "    X_encoded_test = encoder.fit_transform(X_te)\n",
    "    clf2 = joblib.load('Estbasic.pkl') \n",
    "    Predictions = clf2.predict(X_encoded_test.toarray()[-1])\n",
    "    return str(int(Predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowshik\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'23'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Basicpred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L21Night():\n",
    "        #L21 Night\n",
    "        db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "        cursor = db.cursor()\n",
    "        sql = \"SELECT * FROM answers WHERE finished='1'\"\n",
    "        data = frame_query(sql, db)\n",
    "        df_training = data\n",
    "        df_train = df_training[list(data.columns[2:8])+ list(data.columns[10:16])]\n",
    "        Y_train = df_train['L21P'].values\n",
    "        del df_train['L21P']\n",
    "        #ENCODING\n",
    "        X_train = df_train.to_dict('records')\n",
    "        X_tr = []\n",
    "        X_tr.extend(X_train)\n",
    "        #One Hot Encoding \n",
    "        enc = DictVectorizer(sparse = True)\n",
    "        X_encoded_train =enc.fit_transform(X_tr)\n",
    "        estimator = GradientBoostingClassifier() \n",
    "        estimator.fit(X_encoded_train.toarray(),Y_train)\n",
    "        joblib.dump(estimator, 'EstL21.pkl') \n",
    "        return 'success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L21Night()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = 'answers(1).csv'\n",
    "data = pandas.read_csv(URL)\n",
    "data = data[data.finished != 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = data[list(data.columns[2:8])+ list(data.columns[10:15])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BP</th>\n",
       "      <th>Morning Sickness</th>\n",
       "      <th>Breast discomfort</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>UTI Burning maturation</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Weight gain</th>\n",
       "      <th>H/0 Fever</th>\n",
       "      <th>edema</th>\n",
       "      <th>Quickening</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>121212</td>\n",
       "      <td>18</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1212</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age  BP Morning Sickness Breast discomfort  Sugar  \\\n",
       "1000  121212  18              Yes                No   1212   \n",
       "\n",
       "     UTI Burning maturation  Drug  Weight gain H/0 Fever edema Quickening  \n",
       "1000                     No     4           22        No    No         No  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L21pred():\n",
    "    URL = 'DUMB.csv'\n",
    "    DUMB = pandas.read_csv(URL)\n",
    "    df_DUMB = DUMB[DUMB.columns[1:7]+ DUMB.columns[9:14]]\n",
    "\n",
    "    db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "    cursor = db.cursor()\n",
    "    sql = \"SELECT * FROM answers WHERE finished='0'\"\n",
    "    data = frame_query(sql, db)\n",
    "\n",
    "    df_test = data[list(data.columns[2:8])+ list(data.columns[10:15])]\n",
    "    frames = [ df_DUMB,df_test]\n",
    "    df_WH = pandas.concat(frames)\n",
    "\n",
    "    #ENCODING\n",
    "    X_test = df_WH.to_dict('records')\n",
    "    X_te = []\n",
    "    X_te.extend(X_test)\n",
    "\n",
    "\n",
    "    encoder = DictVectorizer(sparse = True)\n",
    "    X_encoded_test = encoder.fit_transform(X_te)\n",
    "    clf2 = joblib.load('EstL21.pkl') \n",
    "    Predictions = clf2.predict(X_encoded_test.toarray()[-1])\n",
    "    return str(int(Predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowshik\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: using '+' to provide set union with Indexes is deprecated, use '|' or .union()\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "URL = 'DUMB.csv'\n",
    "DUMB = pandas.read_csv(URL)\n",
    "df_DUMB = DUMB[DUMB.columns[1:7]+ DUMB.columns[9:14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(data.columns[2:8])+ list(data.columns[10:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowshik\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: using '+' to provide set union with Indexes is deprecated, use '|' or .union()\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "URL = 'DUMB.csv'\n",
    "DUMB = pandas.read_csv(URL)\n",
    "df_DUMB = DUMB[DUMB.columns[1:7]+ DUMB.columns[9:14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BP</th>\n",
       "      <th>Breast discomfort</th>\n",
       "      <th>Drug</th>\n",
       "      <th>H/0 Fever</th>\n",
       "      <th>Morning Sickness</th>\n",
       "      <th>Quickening</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>UTI Burning maturation</th>\n",
       "      <th>Weight gain</th>\n",
       "      <th>edema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>66</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>106</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age   BP Breast discomfort  Drug H/0 Fever Morning Sickness Quickening  \\\n",
       "0   34   66               Yes     3       Yes              Yes        Yes   \n",
       "1   23  106                No     1        No               No         No   \n",
       "\n",
       "   Sugar UTI Burning maturation  Weight gain edema  \n",
       "0     10                    Yes           41   Yes  \n",
       "1      5                     No           45    No  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_DUMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowshik\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: using '+' to provide set union with Indexes is deprecated, use '|' or .union()\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([u'Age', u'BP', u'Breast discomfort', u'Drug', u'H/0 Fever',\n",
       "       u'Morning Sickness', u'Quickening', u'Sugar', u'UTI Burning maturation',\n",
       "       u'Weight gain', u'edema'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DUMB.columns[1:7]+DUMB.columns[9:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L21Night():\n",
    "        #L21 Night\n",
    "        URL = 'answers(1).csv'\n",
    "        data = pandas.read_csv(URL)\n",
    "        data = data[data.finished != 0] \n",
    "        df_training = data\n",
    "        df_train = df_training[list(data.columns[2:8])+ list(data.columns[10:16])]\n",
    "        Y_train = df_train['L21P'].values\n",
    "        del df_train['L21P']\n",
    "        #ENCODING\n",
    "        X_train = df_train.to_dict('records')\n",
    "        X_tr = []\n",
    "        X_tr.extend(X_train)\n",
    "        #One Hot Encoding \n",
    "        enc = DictVectorizer(sparse = True)\n",
    "        X_encoded_train =enc.fit_transform(X_tr)\n",
    "        estimator = GradientBoostingClassifier() \n",
    "        estimator.fit(X_encoded_train.toarray(),Y_train)\n",
    "        joblib.dump(estimator, 'EstL21.pkl') \n",
    "        return 'success'\n",
    "\n",
    "def L21pred():\n",
    "    URL = 'DUMB.csv'\n",
    "    DUMB = pandas.read_csv(URL)\n",
    "    df_DUMB = DUMB[DUMB.columns[1:7]+ DUMB.columns[9:14]]\n",
    "\n",
    "    URL = 'answers(1).csv'\n",
    "    data = pandas.read_csv(URL)\n",
    "    data = data[data.finished != 1] \n",
    "\n",
    "    df_test = data[list(data.columns[2:8])+ list(data.columns[10:15])]\n",
    "    frames = [ df_DUMB,df_test]\n",
    "    df_WH = pandas.concat(frames)\n",
    "\n",
    "    #ENCODING\n",
    "    X_test = df_WH.to_dict('records')\n",
    "    X_te = []\n",
    "    X_te.extend(X_test)\n",
    "\n",
    "\n",
    "    encoder = DictVectorizer(sparse = True)\n",
    "    X_encoded_test = encoder.fit_transform(X_te)\n",
    "    clf2 = joblib.load('EstL21.pkl') \n",
    "    Predictions = clf2.predict(X_encoded_test.toarray()[-1])\n",
    "    return str(int(Predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowshik\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\ipykernel\\__main__.py:25: FutureWarning: using '+' to provide set union with Indexes is deprecated, use '|' or .union()\n",
      "C:\\Users\\Kowshik\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'33'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L21pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>Age</th>\n",
       "      <th>BP</th>\n",
       "      <th>Morning Sickness</th>\n",
       "      <th>Breast discomfort</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>UTI Burning maturation</th>\n",
       "      <th>L11P</th>\n",
       "      <th>L11A</th>\n",
       "      <th>...</th>\n",
       "      <th>Contraseption used</th>\n",
       "      <th>Fetal moments</th>\n",
       "      <th>L32P</th>\n",
       "      <th>L32A</th>\n",
       "      <th>dio-femoral delay</th>\n",
       "      <th>any deficit</th>\n",
       "      <th>Respiratory Rate</th>\n",
       "      <th>L33P</th>\n",
       "      <th>L33A</th>\n",
       "      <th>finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1004</td>\n",
       "      <td>kowshik</td>\n",
       "      <td>121212</td>\n",
       "      <td>18</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1212</td>\n",
       "      <td>No</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     name     Age  BP Morning Sickness Breast discomfort  Sugar  \\\n",
       "1000  1004  kowshik  121212  18              Yes                No   1212   \n",
       "\n",
       "     UTI Burning maturation  L11P  L11A   ...     Contraseption used  \\\n",
       "1000                     No    21    23   ...                    NaN   \n",
       "\n",
       "      Fetal moments L32P L32A dio-femoral delay  any deficit  \\\n",
       "1000            NaN  NaN  NaN               NaN          NaN   \n",
       "\n",
       "      Respiratory Rate L33P  L33A finished  \n",
       "1000               NaN  NaN   NaN        0  \n",
       "\n",
       "[1 rows x 51 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def L31Night():\n",
    "        #L21 Night\n",
    "\n",
    "        \n",
    "        db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "        cursor = db.cursor()\n",
    "        sql = \"SELECT * FROM answers WHERE finished='1'\"\n",
    "        data = frame_query(sql, db)\n",
    "        N='22'\n",
    "        if N == '21':\n",
    "            Questions = list(data.columns[2:8])+ list(data.columns[10:15])\n",
    "            Dumbster = DUMB[DUMB.columns[1:7]+ DUMB.columns[9:14]]\n",
    "        elif N=='22':\n",
    "            Questions = list(data.columns[2:8])+ list(data.columns[17:21])\n",
    "            Dumbster = DUMB.columns[1:7]+ DUMB.columns[16:20]\n",
    "        elif N=='23':\n",
    "            Questions =list(data.columns[2:8])+ list(data.columns[23:27])\n",
    "            Dumbster = DUMB.columns[1:7]+ DUMB.columns[22:26]\n",
    "        else:\n",
    "            Questions = list(data.columns[2:8])+ list(data.columns[29:33])\n",
    "            Dumbster = DUMB.columns[1:7]+ DUMB.columns[28:32]\n",
    "        df_training = data\n",
    "        df_train = df_training[list(Questions + data.columns[35:39] )]\n",
    "        Y_train = df_train['L31P'].values\n",
    "        del df_train['L31P']\n",
    "\n",
    "        #ENCODING\n",
    "        X_train = df_train.to_dict('records')\n",
    "        X_tr = []\n",
    "        X_tr.extend(X_train)\n",
    "        #One Hot Encoding \n",
    "        enc = DictVectorizer(sparse = True)\n",
    "        X_encoded_train =enc.fit_transform(X_tr)\n",
    "        estimator = GradientBoostingClassifier() \n",
    "        estimator.fit(X_encoded_train.toarray(),Y_train)\n",
    "        joblib.dump(estimator, 'EstL31.pkl') \n",
    "        return 'success'\n",
    "\n",
    "def L31pred():\n",
    "\n",
    "\n",
    "\n",
    "    db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "    cursor = db.cursor()\n",
    "    sql = \"SELECT * FROM answers WHERE finished='0'\"\n",
    "    data = frame_query(sql, db)\n",
    "    N='22'\n",
    "    if N == '21':\n",
    "        Questions = list(data.columns[2:8])+ list(data.columns[10:15])\n",
    "        Dumbster = DUMB[DUMB.columns[1:7]+ DUMB.columns[9:14]]\n",
    "    elif N=='22':\n",
    "        Questions = list(data.columns[2:8])+ list(data.columns[17:21])\n",
    "        Dumbster = DUMB.columns[1:7]+ DUMB.columns[16:20]\n",
    "    elif N=='23':\n",
    "        Questions =list(data.columns[2:8])+ list(data.columns[23:27])\n",
    "        Dumbster = DUMB.columns[1:7]+ DUMB.columns[22:26]\n",
    "    else:\n",
    "        Questions = list(data.columns[2:8])+ list(data.columns[29:33])\n",
    "        Dumbster = DUMB.columns[1:7]+ DUMB.columns[28:32]\n",
    "    URL = 'DUMB.csv'\n",
    "    DUMB = pandas.read_csv(URL)\n",
    "    df_DUMB = DUMB[Dumbster + DUMB.columns[34:37] ] \n",
    "    \n",
    "    df_test = data[ Questions + list(data.columns[35:38])]\n",
    "    frames = [ df_DUMB,df_test]\n",
    "    df_WH = pandas.concat(frames)\n",
    "\n",
    "    #ENCODING\n",
    "    X_test = df_WH.to_dict('records')\n",
    "    X_te = []\n",
    "    X_te.extend(X_test)\n",
    "\n",
    "\n",
    "    encoder = DictVectorizer(sparse = True)\n",
    "    X_encoded_test = encoder.fit_transform(X_te)\n",
    "    clf2 = joblib.load('EstL31.pkl') \n",
    "    Predictions = clf2.predict(X_encoded_test.toarray()[-1])\n",
    "    return str(int(Predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def L32Night():\n",
    "\n",
    "\n",
    "    db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "    cursor = db.cursor()\n",
    "    sql = \"SELECT * FROM answers WHERE finished='1'\"\n",
    "    data = frame_query(sql, db)\n",
    "    N='22'\n",
    "    if N == '21':\n",
    "        Questions = list(data.columns[2:8])+ list(data.columns[10:15])\n",
    "        Dumbster = DUMB[DUMB.columns[1:7]+ DUMB.columns[9:14]]\n",
    "    elif N=='22':\n",
    "        Questions = list(data.columns[2:8])+ list(data.columns[17:21])\n",
    "        Dumbster = DUMB.columns[1:7]+ DUMB.columns[16:20]\n",
    "    elif N=='23':\n",
    "        Questions =list(data.columns[2:8])+ list(data.columns[23:27])\n",
    "        Dumbster = DUMB.columns[1:7]+ DUMB.columns[22:26]\n",
    "    else:\n",
    "        Questions = list(data.columns[2:8])+ list(data.columns[29:33])\n",
    "        Dumbster = DUMB.columns[1:7]+ DUMB.columns[28:32]\n",
    "    df_training = data\n",
    "    df_train = df_training[Questions + list(data.columns[40:44])]\n",
    "    Y_train = df_train['L32P'].values\n",
    "    del df_train['L32P']\n",
    "\n",
    "    #ENCODING\n",
    "    X_train = df_train.to_dict('records')\n",
    "    X_tr = []\n",
    "    X_tr.extend(X_train)\n",
    "    #One Hot Encoding \n",
    "    enc = DictVectorizer(sparse = True)\n",
    "    X_encoded_train =enc.fit_transform(X_tr)\n",
    "    estimator = GradientBoostingClassifier() \n",
    "    estimator.fit(X_encoded_train.toarray(),Y_train)\n",
    "    joblib.dump(estimator, 'EstL32.pkl') \n",
    "    return 'success'\n",
    "\n",
    "def L32pred():\n",
    "\n",
    "    db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "    cursor = db.cursor()\n",
    "    sql = \"SELECT * FROM answers WHERE finished='0'\"\n",
    "    data = frame_query(sql, db)\n",
    "    URL = 'DUMB.csv'\n",
    "    DUMB = pandas.read_csv(URL)\n",
    "    N='22'\n",
    "    if N == '21':\n",
    "        Questions = list(data.columns[2:8])+ list(data.columns[10:15])\n",
    "        Dumbster = DUMB[DUMB.columns[1:7]+ DUMB.columns[9:14]]\n",
    "    elif N=='22':\n",
    "        Questions = list(data.columns[2:8])+ list(data.columns[17:21])\n",
    "        Dumbster = DUMB.columns[1:7]+ DUMB.columns[16:20]\n",
    "    elif N=='23':\n",
    "        Questions =list(data.columns[2:8])+ list(data.columns[23:27])\n",
    "        Dumbster = DUMB.columns[1:7]+ DUMB.columns[22:26]\n",
    "    else:\n",
    "        Questions = list(data.columns[2:8])+ list(data.columns[29:33])\n",
    "        Dumbster = DUMB.columns[1:7]+ DUMB.columns[28:32]\n",
    "    \n",
    "\n",
    "    df_DUMB = DUMB[Dumbster + DUMB.columns[39:42] ] \n",
    "    \n",
    "    df_test = data[ Questions + list(data2.columns[40:43])]\n",
    "    frames = [ df_DUMB,df_test]\n",
    "    df_WH = pandas.concat(frames)\n",
    "\n",
    "    #ENCODING\n",
    "    X_test = df_WH.to_dict('records')\n",
    "    X_te = []\n",
    "    X_te.extend(X_test)\n",
    "\n",
    "\n",
    "    encoder = DictVectorizer(sparse = True)\n",
    "    X_encoded_test = encoder.fit_transform(X_te)\n",
    "    clf2 = joblib.load('EstL32.pkl') \n",
    "    Predictions = clf2.predict(X_encoded_test.toarray()[-1])\n",
    "    return str(int(Predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def L33Night():\n",
    "        #L21 Night\n",
    "\n",
    "        \n",
    "        db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "        cursor = db.cursor()\n",
    "        sql = \"SELECT * FROM answers WHERE finished='1'\"\n",
    "        data = frame_query(sql, db)\n",
    "        N='22'\n",
    "        if N == '21':\n",
    "            Questions = list(data.columns[2:8])+ list(data.columns[10:15])\n",
    "            Dumbster = DUMB[DUMB.columns[1:7]+ DUMB.columns[9:14]]\n",
    "        elif N=='22':\n",
    "            Questions = list(data.columns[2:8])+ list(data.columns[17:21])\n",
    "            Dumbster = DUMB.columns[1:7]+ DUMB.columns[16:20]\n",
    "        elif N=='23':\n",
    "            Questions =list(data.columns[2:8])+ list(data.columns[23:27])\n",
    "            Dumbster = DUMB.columns[1:7]+ DUMB.columns[22:26]\n",
    "        else:\n",
    "            Questions = list(data.columns[2:8])+ list(data.columns[29:33])\n",
    "            Dumbster = DUMB.columns[1:7]+ DUMB.columns[28:32]\n",
    "        df_training = data\n",
    "        df_train = df_training[Questions + list(data.columns[45:49])]\n",
    "        Y_train = df_train['L32P'].values\n",
    "        del df_train['L32P']\n",
    " \n",
    "        #ENCODING\n",
    "        X_train = df_train.to_dict('records')\n",
    "        X_tr = []\n",
    "        X_tr.extend(X_train)\n",
    "        #One Hot Encoding \n",
    "        enc = DictVectorizer(sparse = True)\n",
    "        X_encoded_train =enc.fit_transform(X_tr)\n",
    "        estimator = GradientBoostingClassifier() \n",
    "        estimator.fit(X_encoded_train.toarray(),Y_train)\n",
    "        joblib.dump(estimator, 'EstL32.pkl') \n",
    "        return 'success'\n",
    "\n",
    "def L33pred():\n",
    "\n",
    "\n",
    "    db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"ge_hackathon\" )\n",
    "    cursor = db.cursor()\n",
    "    sql = \"SELECT * FROM answers WHERE finished='0'\"\n",
    "    data = frame_query(sql, db)\n",
    "    URL = 'DUMB.csv'\n",
    "    DUMB = pandas.read_csv(URL)\n",
    "    N='22'\n",
    "    if N == '21':\n",
    "        Questions = list(data.columns[2:8])+ list(data.columns[10:15])\n",
    "        Dumbster = DUMB[DUMB.columns[1:7]+ DUMB.columns[9:14]]\n",
    "    elif N=='22':\n",
    "        Questions = list(data.columns[2:8])+ list(data.columns[17:21])\n",
    "        Dumbster = DUMB.columns[1:7]+ DUMB.columns[16:20]\n",
    "    elif N=='23':\n",
    "        Questions =list(data.columns[2:8])+ list(data.columns[23:27])\n",
    "        Dumbster = DUMB.columns[1:7]+ DUMB.columns[22:26]\n",
    "    else:\n",
    "        Questions = list(data.columns[2:8])+ list(data.columns[29:33])\n",
    "        Dumbster = DUMB.columns[1:7]+ DUMB.columns[28:32]\n",
    "    \n",
    "\n",
    "    df_DUMB = DUMB[Dumbster + DUMB.columns[44:47]] \n",
    "    \n",
    "    df_test = data[ Questions + list(data.columns[45:48])]\n",
    "    frames = [ df_DUMB,df_test]\n",
    "    df_WH = pandas.concat(frames)\n",
    "\n",
    "    #ENCODING\n",
    "    X_test = df_WH.to_dict('records')\n",
    "    X_te = []\n",
    "    X_te.extend(X_test)\n",
    "\n",
    "\n",
    "    encoder = DictVectorizer(sparse = True)\n",
    "    X_encoded_test = encoder.fit_transform(X_te)\n",
    "    clf2 = joblib.load('EstL32.pkl') \n",
    "    Predictions = clf2.predict(X_encoded_test.toarray()[-1])\n",
    "    return str(int(Predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_training = data\n",
    "df_train = df_training[list(data.columns[2:8])+ list(data.columns[29:34] + )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = 'answers(1).csv'\n",
    "data = pandas.read_csv(URL)\n",
    "data = data[data.finished != 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(df_training.columns[33:37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'dio-femoral delay', u'any deficit', u'Respiratory Rate'], dtype='object')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[45:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'dio-femoral delay', u'any deficit', u'Respiratory Rate'], dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DUMB.columns[44:47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Blurring', u'Contraseption used', u'Fetal moments'], dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DUMB.columns[39:42] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "URL = 'DUMB.csv'\n",
    "DUMB = pandas.read_csv(URL)\n",
    "#df_DUMB = DUMB[DUMB.columns[1:7]+ DUMB.columns[26:32] + ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Sudden in Weight', u'Thyroid swelling', u'JVP', u'TPR'], dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DUMB.columns[28:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'UTI last stage', u'Backache', u'Labour pain'], dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DUMB.columns[34:37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UTI last stage', 'Backache', 'Labour pain']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns[35:38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'UTI last stage', u'Backache', u'Labour pain'], dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[35:38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
